---
title: "Introduction to spNetwork"
author: "Jeremy Gelb"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    fig_width: 5
    fig_height: 5
    toc: true
    toc_depth: 2
    df_print: "tibble"
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```



This vignette is a short introduction to the **spNetwork** package. It will present the main features of the package by using datasets provided with the package.


## Network Kernel Density Estimate

The first feature of the package is the Network Kernel Density Estimate (NKDE).

A classical KDE proposes to estimate the density of a set of events in a two dimensional space. That space is separated in pixels, and the density is estimated for each pixel.

This approach is not adapted to analyze density of events occuring on a network, like accidents and crimes in streets, or breaks on a network of water pipes. Indeed, calculating densities for locations outside the network is meaningless and the euclidean distance underestimates the real distance between two object on the network.

A NKDE extends the classical KDE by :

* using lixels intead of pixels. A lixel is a linear equivalent of a pixel on a network. The lines of the network are splitted into lixels according to a chosen resolution.
* calculating reticular distances between objects instead of euclidean distances.

An image is worth 1000 words, so let us consider this situation : 
<center>
![Image Title](images/situation-01.png){width=300px}
</center>

Each red point is an event and the lines constitute the network. One could realize a simple KDE on that dataset and would obtain something like :

<center>
![Image Title](images/simple_kde-01.png){width=300px}
</center>

But this is only partly satisfying if we are interested in the density of the envents on the network.

To perform a NKDE, the lines of the network must be splitted into lixels : chunks of line of the same length. They are similar to pixels, but in a one dimensional space.

<center>
![Image Title](images/lixels_example-01.png){width=300px}
</center>

The densities will be evaluated for the center of each lixel. The second step is to snapp the points to the network. At that point we have everything to perform the NKDE, we just need to define ther kernel function and the kernel range.

The kernel range will be used to calculate which events are close enough to the center of each lixel center to be used in their density estimation.

<center>
![Image Title](images/centroid_lixel-01.png){width=300px}
</center>

The final result would look like this picture :

<center>
![Image Title](images/nkde_simple-01.png){width=300px}
</center>

It is important to note that the density is not evluated for planar units (m<sup>2</sup>) but for linear units (m).

Indeed, the density $\lambda$ for a lixel *l* is estimated as follow 

$\lambda(l) = \sum_{i=1}^n \dfrac{1}{r}k(\dfrac{d_{il}}{r})$

With a range *r* and *n* events for which the distance between each event *i* and *l* (*d<sub>il</sub>*) is smaller than *r*. K is the kernel function.

This differs from the original estimation for planar data : 

$\lambda(l) = \sum_{i=1}^n \dfrac{1}{r^2}k(\dfrac{d_{il}}{r})$

The three most used kernel functions actually implemented are : 

* the gaussian kernel : $k(\dfrac{d_{il}}{r})=\dfrac{1}{\sqrt{2\pi}} * \exp(-\dfrac{d_{il}^2}{2r^2})$

* the quartic kernel : $k(\dfrac{d_{il}}{r})=\dfrac{3}{\pi} * (1-\dfrac{d_{il}^2}{r^2})$

* the epanechnikov kernel : $k(\dfrac{d_{il}}{r})=\dfrac{3}{4}*(1-\dfrac{d_{il}^2}{r^2})$

for more details on NKDE, please read  Xie et Yan (2008;2013).

The **spNetwork** package makes this type of analyse straightforward in R. The main problem of the implementation of the NKDE is to reduce computation time. Indeed, on a large dataset, building the network and evaluating the distances between each event and each lixel center would be too long and could lead to memory issues.

To avoid this, the first solution provided in **spNetwork** is a grided application of the NKDE. The user can split the study area with a grid, the calculation is then performed in each cell of the grid. A buffer is applied on each cell to avoid frontier effect.

A verbose parameter allows to control how much information the user wants about the progressing of the process. We set it here to "silent" to keep the document readable, but typically one would prefere "text" or "progressbar".

```{r message=FALSE, warning=FALSE}

#first load data and packages
library(spNetwork)
library(sp)
library(maptools)
library(rgeos)
data(mtl_network)
data(bike_accidents)

#then plotting the data
plot(mtl_network)
plot(bike_accidents,add=T,col='red')


#then applying the NKDE
lixels <- nkde(mtl_network,bike_accidents,
            snap_dist = 150,
            lx_length=200,mindist=50,
            kernel_range = 300, kernel='quartic',
            weights=NULL, grid_shape = c(5,5),
            verbose = "silent")
```

We could then map the densities estimated for each lixel
```{r message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
library(RColorBrewer)
library(classInt)

## a little function to help the mapping
get_colors <-function(x,colors,breaks){
  mycolors <- sapply(x,function(xi){
    for(i in seq(1:length(colors))){
      if (xi<breaks$brks[[i+1]]){
        return(colors[[i]])
      }
    }
    return(colors[[length(colors)]])
  })
  return(mycolors)
}

#setting an easier scale for mapping
lixels$mapdensity <- round(lixels$density*1000,4)

#using a discretization method
breaks <- classIntervals(lixels$mapdensity, n = 7, style = "fisher", intervalClosure = "right")
PaletteCouleur <- brewer.pal(n = 7, name = "Spectral")
PaletteCouleur <- rev(PaletteCouleur)
lixels$class <- get_colors(lixels$mapdensity,PaletteCouleur, breaks)

#and finally map with ggplot
labels <- names(print(breaks))
MapData <- fortify(lixels,id="lxid")
MapData$id <- as.numeric(MapData$id)
MapData <- left_join(MapData, lixels@data, by=c("id"="lxid"))
ggplot(MapData) + 
  geom_path(aes(x=long,y=lat,group=group,color=class))+
  scale_color_manual("density",
    breaks = PaletteCouleur, values = PaletteCouleur, 
    label = labels)+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  coord_fixed()+
  ggtitle("bike accident density by kilometers in 2016",
          subtitle = "within a radius of 300 meters")
  

```

As you can imagine it remains a costly process, but an embarrassingly parallel one. Indeed, nothing makes this process strictly sequential. The calculus of the NKDE for each cell could be done by several cores. **spNetwork** provides a function nkde_grided.mc, able to split the work between processes. More specifically, it uses functions from the packages **future** and **future.apply**. The selection of the plan is let to the user to permit the best compatibility on each os and computer. One could even paralellize this calculation on several computers. See the documentation of the **future** package if needed.

Let us split the work between 4 cores.
```{r}

#setting the multiprocess plan
future::plan(future::multiprocess(workers=4))

#then applying the NKDE
lixels_mc <- nkde.mc(mtl_network,bike_accidents,
            snap_dist = 150,
            lx_length=200,mindist=50,
            kernel_range = 300, kernel='quartic',
            weights=NULL, grid_shape = c(5,5),
            verbose = "silent")

# let's set back the classical sequential plan
if (!inherits(future::plan(), "sequential")) future::plan(future::sequential)

#we can compare the previous result and the new one
diff <- sum(abs(lixels_mc$density - lixels$density))
print(paste("overall difference between the regular and paralellized method : ",round(diff,8),sep=""))

```


## Spatial matrices

A vast number of spatial analysis methods are based on a spatial matrix W<sub>ij</sub> of size  *n* x *n* with *i* an observation and *j* the neighbours of that observation. W<sub>ij</sub> represents the degree of spatial relationship between i and j.

Classicaly one can define : 

* neighbouring matrices (W<sub>ij</sub> = 1 if *j* is a neighbour of *i*)
* distance matrices (W<sub>ij</sub> = the distance between i and j, modified by a function like 1/distance or 1/distance**2)
* interraction matrices (W<sub>ij</sub> = the degree of interraction between *i* and *j*, the measure of the interraction depends on the subject of the analysis)

In R, the classical package to deal with such object is the package **spdep** which defines objects like neighbour lists and spatial weight lists, and offers the possibility to convert such objects into regular matrices.

When one works with data constrained on a network, using euclidean distance to estimate proximity between observation tends to overstimate the real proximity of observations.

**spNetwork** offers the possibility to create listw objects for SpatialLinesDataFrame based on reticular distance. Lets give an exemple here : calculating the Moran I for the number of bike accidents recorded on the montreal road network in 2016.

We will use here the function *network_listw*. The distances can be calculated from the centroids of the lines, from the ends of the lines or from evenly spaced points on the lines. We will use here the ends method.

let us consider that above 300 meters two segments are not neighbours anymore, and convert the distances between the observations into spatial weights with the inverse of the squared distance

```{r}
library(spdep)
data(mtl_network)

netlistw <- network_listw(mtl_network,mtl_network,
                           method = "ends",
                           mindist = 10,
                           maxdistance = 300,
                           dist_func = "squared inverse",
                           line_weight = 'length',
                           matrice_type = 'W',
                           grid_shape = c(5,5),
                           verbose='silent')

Test <- moran.test(mtl_network$nbAccident, netlistw, zero.policy = T)
print(round(Test$estimate,4))

```

One could go further and define its own function to convert distances into spatial weights

```{r}
my_conv_func <- function(x){
  if (x>=300){
    return(0)
  }else{
    return(1/x**3)
  }
}

netlistw2 <- network_listw(mtl_network, mtl_network,
                             method = "ends",
                             mindist = 10,
                             maxdistance = 300,
                             dist_func = my_conv_func,
                             line_weight = 'length',
                             matrice_type = 'W',
                             grid_shape = c(5,5),
                             verbose='silent')

Test2 <- moran.test(mtl_network$nbAccident, netlistw2, zero.policy = T)
print(round(Test2$estimate,4))
```

We can also use the mutliprocess version of the function. Let us use it to calculate a local version of the Moran Index.

```{r}

#setting the multiprocess plan
future::plan(future::multiprocess(workers=4))

netlistw3 <- network_listw.mc(mtl_network, mtl_network,
                             method = "ends",
                             mindist = 10,
                             maxdistance = 300,
                             dist_func = my_conv_func,
                             line_weight = 'length',
                             matrice_type = 'W',
                             grid_shape = c(5,5),
                             verbose='silent')

if (!inherits(future::plan(), "sequential")) future::plan(future::sequential)

Lisa <- localmoran(mtl_network$nbAccident,netlistw3, zero.policy = T)
```

We could now map that local Moran I


```{r}
spLisa <- mtl_network
spLisa$pval <- Lisa[,5]
spLisa$Imoran <- round(Lisa[,1],3)

## a little function to help the mapping
get_colors <-function(x,colors,breaks){
  mycolors <- sapply(x,function(xi){
    for(i in seq(1:length(colors))){
      if (xi<breaks$brks[[i+1]]){
        return(colors[[i]])
      }
    }
    return(colors[[length(colors)]])
  })
  return(mycolors)
}

#using a discretization method
breaks <- classIntervals(spLisa$Imoran, n = 7, style = "fisher", intervalClosure = "right")
PaletteCouleur <- brewer.pal(n = 7, name = "Spectral")
PaletteCouleur <- rev(PaletteCouleur)
spLisa$class <- get_colors(spLisa$Imoran,PaletteCouleur, breaks)

#lets keep in color only the observations with a p-value <= 0.05
spLisa$class <- ifelse(spLisa$pval<=0.05, spLisa$class, "grey")
labels <- names(print(breaks))
labels[[length(labels)+1]] <- "not.sign"
PaletteCouleur[[length(PaletteCouleur)+1]] <- "grey"

#and finally map with ggplot
MapData <- fortify(spLisa)
MapData <- merge(MapData, spLisa@data, by.x="id", by.y=0)

ggplot(MapData) + 
  geom_path(aes(x=long,y=lat,group=group,color=class))+
  scale_color_manual("local moran I",
    breaks = PaletteCouleur, values = PaletteCouleur, 
    label = labels)+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  coord_fixed()+
  ggtitle("Spatial autocorrelation of bike accidents in 2016")

```

## combining NKDE and Local Moran I

As proposed by Xie et Yan (2013), one could perform an analysis in two steps : 

1. First, split the network in lixels and calculate the NKDE for these lixels
2. Second, calculate the Local Moran I on each lixel for the density estimated values to identify significant hot and cold spots

With the **spNetwork** package, this type of analysis is really simple to perform.

```{r}
#setting the multiprocess plan
future::plan(future::multiprocess(workers=4))

print("calculating the lixels density ...")
#then applying the NKDE
lixels <- nkde.mc(mtl_network,bike_accidents,
            snap_dist = 150,
            lx_length=150,mindist=50,
            kernel_range = 300, kernel='quartic',
            weights=NULL, grid_shape = c(5,5),
            verbose = "silent")


#now, preparing the neighbouring matrix
# because lixels have same lengths, we will use the centered version,
# and considere a maximum distance of kernel_range + lx_length

print("building the spatial matrix ...")
netlistw4 <- network_listw.mc(lixels, mtl_network,
                                 method="centroid",
                                 maxdistance = 450,
                                 dist_func = "squared inverse",
                                 line_weight = 'length',
                                 matrice_type = 'W',
                                 grid_shape = c(5,5),
                                 verbose='silent')

#we can now calculate the local Moran I
Lisa <- localmoran(lixels$density,netlistw4, zero.policy = T)

# lets set back the classical sequential plan
if (!inherits(future::plan(), "sequential")) future::plan(future::sequential)
```

Again, it is easy to map the results in R, but remember that the results could also be exported as a shapefile or a geopackage with the function *writeOGR* from the package **rgdal**

```{r}
spLisa <- lixels
spLisa$pval <- Lisa[,5]
spLisa$Imoran <- round(Lisa[,1],3)

#lets identify the 4 quadrats of the Moran I
X <- lixels$density
WX <- lag.listw(netlistw4,lixels$density, zero.policy = T)

spLisa$moran_class <- case_when(
  X>mean(X) & WX>mean(WX) & spLisa$pval<0.05 ~ "HH",
  X<mean(X) & WX<mean(WX) & spLisa$pval<0.05 ~ "LL",
  X>mean(X) & WX<mean(WX) & spLisa$pval<0.05 ~ "HL",
  X<mean(X) & WX>mean(WX) & spLisa$pval<0.05 ~ "LH",
  TRUE ~ "not.sign")


#rebuilding the rownames
spLisa2 <- sp::spChFIDs(spLisa, as.character(1:nrow(spLisa)))

#and finally map with ggplot
MapData <- fortify(spLisa2)
MapData <- merge(MapData, spLisa2@data, by.x="id", by.y=0)

PaletteCouleur<- c("red", "blue", "lightpink", "skyblue2", "gray")

ggplot(MapData) + 
  geom_path(aes(x=long,y=lat,group=group,color=moran_class))+
  scale_color_manual("local moran I class",
    breaks = c("HH","LL","HL","LH","not.sign"), values = PaletteCouleur, 
    label = c("HH","LL","HL","LH","not.sign"))+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  coord_fixed()+
  ggtitle("Hot spots of bike accidents kernel density in 2016")

```

```{r eval=FALSE, include=FALSE}
# spLisa <- lixels
# spLisa$pval <- Lisa[,5]
# spLisa$Imoran <- round(Lisa[,1],3)
# 
# ## a little function to help the mapping
# get_colors <-function(x,colors,breaks){
#   mycolors <- sapply(x,function(xi){
#     for(i in seq(1:length(colors))){
#       if (xi<breaks$brks[[i+1]]){
#         return(colors[[i]])
#       }
#     }
#     return(colors[[length(colors)]])
#   })
#   return(mycolors)
# }
# 
# #using a discretization method
# breaks <- classIntervals(spLisa$Imoran, n = 7, style = "fisher", intervalClosure = "right")
# PaletteCouleur <- brewer.pal(n = 7, name = "Spectral")
# PaletteCouleur <- rev(PaletteCouleur)
# spLisa$class <- get_colors(spLisa$Imoran,PaletteCouleur, breaks)
# 
# #lets keep in color only the observations with a p-value <= 0.05
# spLisa$class <- ifelse(spLisa$pval<=0.05, spLisa$class, "grey")
# labels <- names(print(breaks))
# labels[[length(labels)+1]] <- "not.sign"
# PaletteCouleur[[length(PaletteCouleur)+1]] <- "grey"
# 
# #rebuilding the rownames
# spLisa2 <- sp::spChFIDs(spLisa, as.character(1:nrow(spLisa)))
# 
# #and finally map with ggplot
# MapData <- fortify(spLisa2)
# MapData <- merge(MapData, spLisa2@data, by.x="id", by.y=0)
# 
# ggplot(MapData) + 
#   geom_path(aes(x=long,y=lat,group=group,color=class))+
#   scale_color_manual("local moran I",
#     breaks = PaletteCouleur, values = PaletteCouleur, 
#     label = labels)+
#   theme(axis.title.x=element_blank(),
#         axis.text.x=element_blank(),
#         axis.ticks.x=element_blank(),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank()) +
#   coord_fixed()+
#   ggtitle("Spatial autocorrelation of bike accidents kernel density in 2016")

```

## Other features

Some words about complementary features : 

1. For all the above presented methods, one can define the cost of traveling on a line (the base value is the geographical length)
2. For all the above presented methods, one can define directions on the lines


## Upcoming features

1. Allow to define a weight on the lines for both directions
2. something else ?

# References

Xie, Z., & Yan, J. (2008). Kernel density estimation of traffic accidents in a network space. Computers, environment and urban systems, 32(5), 396-406.

Xie, Z., & Yan, J. (2013). Detecting traffic accident clusters with network kernel density estimation and local spatial statistics: an integrated approach. Journal of transport geography, 31, 64-71.
